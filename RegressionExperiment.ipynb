# -*- coding: utf-8 -*-
from numpy import *
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.externals.joblib import Memory
from sklearn.datasets import load_svmlight_file
import matplotlib.pyplot as plt
#import time
import warnings
warnings.filterwarnings("ignore")
mem = Memory("./mycache")
@mem.cache

def get_data():
    data = load_svmlight_file("C:/Users/wangyu/Desktop/housing_scale.txt")
    return data[0], data[1]


def model(theta,x,y):  #模型
    return ((x.dot(theta)-y)**2).sum()/2
 
def grad(theta,x,y):     #梯度计算
    return x.T.dot(x.dot(theta)-y)

X, y = get_data()

X=X.toarray()

X=np.c_[np.ones(len(X)),X]#在训练集前添加一列1
#切割数据集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

theta = np.zeros(X_train.shape[1])

L_train = []
L_validaion = []
iters = 100#迭代次数
for i in range(iters):
    G = grad(theta,X_train,y_train)
    learning_rate = 0.001#学习率
    
    theta = theta - learning_rate*G#更新theta
    L_train.append(model(theta,X_train,y_train))
    L_validaion.append(model(theta,X_test,y_test))
 
plt.plot(range(iters),L_train, label='train loss')
plt.plot(range(iters),L_validaion, label='validtion loss')
plt.xlabel('iters')#横坐标
plt.ylabel('loss')#纵坐标
plt.legend()
plt.show()
 